# Session Log - 2026-02-15

## 今日主题

- `graph_chunk_entity_relation.graphml` 文件用途
- `asyncio` / event loop 基础
- `insert` 与 `ainsert` 关系
- `__post_init__` 调用机制
- `_insert_start` 与 `index_start_callback`

## 关键结论

1. `graph_chunk_entity_relation.graphml` 是图缓存（知识图谱持久化）
2. `insert()` 是 `ainsert()` 的同步封装，核心是 `run_until_complete(...)`
3. 默认执行模型是单线程 event loop 上的协程并发
4. `GraphRAG.__post_init__` 由 dataclass 自动触发
5. 默认 `NetworkXStorage` 的 `index_start_callback` 是空实现；`Neo4jStorage` 才有实际初始化逻辑

## 对应主题文档

- `learn/topics/storage-graphml.md`
- `learn/topics/asyncio-event-loop.md`
- `learn/topics/extract-entities-flow.md`
- `learn/topics/merge-nodes-then-upsert.md`
- `learn/topics/merge-edges-then-upsert.md`
- `learn/topics/default-entity-extraction-prompt.md`
- `learn/topics/networkx-community-schema.md`
- `learn/topics/pack-single-community-describe.md`
- `learn/topics/default-community-report-prompt.md`
- `learn/topics/prompt-customization-by-domain.md`
- `learn/topics/local-vs-global-query.md`
- `learn/topics/global-query-flow.md`
- `learn/topics/global-map-rag-points-prompt.md`
- `learn/topics/global-reduce-rag-response-prompt.md`
- `learn/topics/local-query-flow.md`

## 问答速记

- Q: `new_docs = {k: v for k, v in new_docs.items() if k in _add_doc_keys}` 是什么？
  A: 这是 Python 的字典推导式（dict comprehension），结果仍然是字典。它从 `new_docs` 中筛选键在 `_add_doc_keys` 里的项，常用于“去掉已存在文档，只保留需要新增的文档”。
- Q: `self.full_docs` 是否对应 `nano_graphrag_cache_llm_TEST/kv_store_full_docs.json`？
  A: 是。`GraphRAG.__post_init__` 用 `namespace=\"full_docs\"` 初始化 KV 存储，`JsonKVStorage` 会把它映射到 `working_dir/kv_store_full_docs.json`。对应：`nano_graphrag/graphrag.py:173`，`nano_graphrag/_storage/kv_json.py:14`。
- Q: 为什么说 `JsonKVStorage` 实现优雅？
  A: 它是“内存字典 + 生命周期落盘”的轻量设计：初始化时 `load_json` 到 `self._data`，增量写入只做 `dict.update`，在 `index_done_callback` 统一 `write_json` 持久化。对应：`nano_graphrag/_storage/kv_json.py:15`，`nano_graphrag/_storage/kv_json.py:43`，`nano_graphrag/_storage/kv_json.py:22`。
- Q: `overlap_token_size` 是干什么的？为什么 `range` 步长是 `max_token_size - overlap_token_size`？
  A: 这是滑动窗口分块。每块最多 `max_token_size`，相邻块保留 `overlap_token_size` 的重叠上下文，避免在边界处丢语义。实现上用较小步长前进（`window_size - overlap`），所以看起来是“一小步一小步加”。对应：`nano_graphrag/_op.py:42`、`nano_graphrag/_op.py:43`。
- Q: RAG 里为什么要让 chunk 之间重叠？
  A: 主要是为了解决“边界切断语义”问题。很多关键信息会跨句或跨段，若刚好被切在两个 chunk 之间，不重叠会导致单个 chunk 看不到完整上下文，从而影响 embedding 召回和后续生成。重叠能提升召回稳定性，但会增加存储与检索成本，需要在效果和成本间折中。
- Q: `if self.enable_naive_rag: await self.chunks_vdb.upsert(inserting_chunks)` 是做什么的？
  A: 这是给“naive RAG 模式”建 chunk 向量索引。只有开启 `enable_naive_rag=True` 才会创建 `chunks_vdb` 并写入；默认配置下它不会执行。后续只有 `QueryParam(mode="naive")` 查询才会走这套路径。
- Q: chunking 这段代码里做了 embedding 吗？
  A: `get_chunks(...)` 只做 token 化 + 切块 + 生成 chunk id，不做向量化。只有在 `chunks_vdb.upsert(inserting_chunks)`（naive 模式）或 `entity_vdb.upsert(...)`（实体向量）时才会调用 embedding 模型生成向量。对应：`nano_graphrag/_op.py:100`、`nano_graphrag/_storage/vdb_nanovectordb.py:45`、`nano_graphrag/_op.py:413`。
- Q: 为什么 GraphRAG 是先抽实体关系，再做 embedding？
  A: 这是 GraphRAG 的核心取舍：它优先构建“实体-关系-社区”结构，再对实体做向量化，检索时可结合语义相似度和图结构（邻接、多跳、社区报告），比只用 chunk 向量更适合复杂推理。另一个工程原因是先做实体合并再 embedding，能减少重复实体的向量计算。默认 chunk 向量仅在 naive 模式下启用。
- Q: `extract_entities` 的整体流程是什么？
  A: 先按 chunk 并发调用 LLM 结构化抽取（支持补抽循环），再解析成实体/关系记录；随后跨 chunk 合并去重并写入图（节点/边），对过长描述做摘要压缩；最后在 `entity_vdb` 存在时写入实体向量索引。详见 `learn/topics/extract-entities-flow.md`。
- Q: 日志里 `entities(duplicated)` / `relations(duplicated)` 是严格“重复数量”吗？
  A: 不是严格重复计数。这里累加的是每个 chunk 内当前字典的 key 数（`len(maybe_nodes)`/`len(maybe_edges)`），跨 chunk 同名实体会重复计入，所以更准确是“未全局去重前的累计抽取量”。日志里的 `duplicated` 更像提示“包含重复”，而不是“重复项个数”。
- Q: `maybe_edges[tuple(sorted(k))].extend(v)` 为什么要 `sorted`？
  A: 因为这里把关系当作无向边处理，同一条边 `(A, B)` 和 `(B, A)` 需要归一成同一个 key。`tuple(sorted(k))` 就是在做“规范化键”，避免同一关系被分到两个桶里。
- Q: `_merge_nodes_then_upsert` 做了什么？
  A: 它是“同名实体归并器”：读取已有节点 + 合并本轮抽取结果，按频次确定 `entity_type`，合并去重 `source_id/description`，必要时摘要压缩描述，然后 `upsert_node`。返回值会被后续实体向量索引流程复用。详见 `learn/topics/merge-nodes-then-upsert.md`。
- Q: `_merge_edges_then_upsert` 做了什么？
  A: 它是“同一实体对关系归并器”：读取已有边并合并本轮关系，`order` 取最小、`weight` 累加、`description/source_id` 去重拼接，必要时补 `UNKNOWN` 节点并做描述摘要，最后 `upsert_edge`。详见 `learn/topics/merge-edges-then-upsert.md`。
- Q: `_merge_edges_then_upsert` 里的 `order` 和 `weight` 分别是什么？
  A: `weight` 是关系强度分数（抽取时来自 relationship strength，合并时会累加），后续 local 检索排序会使用它；`order` 是关系阶数（1=直接，2/3=高阶间接关系），合并时取最小值。默认 prompt 抽取路径通常没有 `order`，会回退为 1；DSPy 路径才会显式产出 `order` 字段。
- Q: 默认 `entity_extraction` prompt 在说什么？
  A: 它要求模型按固定格式抽取“实体+关系”，并用指定分隔符输出英文结构化列表，最后输出 completion 标记。这种设计便于后续稳定解析和合并。详见 `learn/topics/default-entity-extraction-prompt.md`。
- Q: `extract_entities` 能否总结为“提取/去重/合并节点边，并把节点保存在 `vdb_entities.json`”？
  A: 基本正确，但需补两点：1) 节点和边首先写入图存储（默认 `graph_chunk_entity_relation.graphml`）；2) `vdb_entities.json` 只存实体向量索引，而且仅在 `entity_vdb` 启用时写入。
- Q: `self.chunk_entity_relation_graph = maybe_new_kg` 是不是多余？`knwoledge` 是不是拼错了？
  A: 在当前默认实现里 `entity_extraction_func` 通常返回同一个图实例，所以赋值看起来是冗余；但这个字段是可插拔的（可换自定义函数），保留赋值能兼容“返回新图对象”的扩展实现。`knwoledge` 的确是 `knowledge` 的拼写错误，代码里是历史命名遗留。
- Q: `await self.chunk_entity_relation_graph.clustering(self.graph_cluster_algorithm)` 和 `_leiden_clustering` 在做什么？
  A: 这是把实体关系图做社区聚类。默认算法是 `leiden`：先取最大连通子图并做稳定化，再跑分层 Leiden，得到每个节点在不同层级的 cluster id，最后把 `clusters` 写回节点属性。后续 `community_schema` / `generate_community_report` / global-local 检索都会依赖这些聚类结果。
- Q: `_leiden_clustering` 是否就是把大图分层聚类并更新节点 `clusters` 字段？
  A: 是。更精确地说，它不会直接生成多个“子图对象”，而是把每个节点所属的多层社区标签写回节点属性 `clusters`（JSON 字符串）。后续再由 `community_schema` 基于这些标签构建社区视图。
- Q: Leiden 算法是通用的吗？
  A: 是通用的图社区发现算法，不局限于 GraphRAG。它可用于社交网络、引文网络、知识图谱等，只要能表示成图就能尝试；但效果依赖图质量、目标函数与参数设置，且其随机性需要通过 seed 控制复现性。
- Q: `NetworkXStorage.community_schema` 在做什么？
  A: 它不负责聚类，而是把节点上的 `clusters` 标签聚合成社区视图（nodes/edges/chunk_ids/sub_communities/occurrence），供社区报告生成与 global 检索使用。详见 `learn/topics/networkx-community-schema.md`。
- Q: `_pack_single_community_describe` 在做什么？
  A: 它负责把单个社区打包成 LLM 可消费的描述文本（Reports/Entities/Relationships 三段 CSV），并在 token 预算内按重要性做截断；大社区时可优先引用子社区报告并去重节点/边。详见 `learn/topics/pack-single-community-describe.md`。
- Q: `PROMPTS["community_report"]` 在说什么？
  A: 它定义了社区报告生成任务：要求输出包含 title/summary/rating/rating_explanation/findings 的标准 JSON，并遵循“只基于证据、不要编造”的 grounding 规则。详见 `learn/topics/default-community-report-prompt.md`。
- Q: 为什么 `rating` 看起来很怪？
  A: 因为它是 LLM 给的社区级启发式分（软信号），不是严格标注真值。代码里它主要用于社区过滤/排序和 map 阶段上下文字段；默认阈值为 0，可不依赖它做硬过滤。详见 `learn/topics/default-community-report-prompt.md`。
- Q: 是否需要按场景重设 prompt（如 entity types）？
  A: 需要。默认 prompt 偏通用，领域场景通常要改实体类型、抽取规则与社区评分 rubric。并且改 prompt 后若不清缓存，`insert` 可能因 doc/chunk 去重而不重跑抽取。详见 `learn/topics/prompt-customization-by-domain.md`。
- Q: `local query` 和 `global query` 有什么区别？
  A: `local` 是“实体中心”检索（先向量召回实体，再扩展关系/文本/社区）；`global` 是“社区中心”检索（先筛社区报告，再 map-reduce 汇总回答），更偏全局总结。详见 `learn/topics/local-vs-global-query.md`。
- Q: `global_query` 的完整流程是怎样的？
  A: 先取社区 schema 并按 level/occurrence/rating 过滤排序，再按 token 预算分组做 map（每组提炼 points+score），随后聚合并截断 points，最后走 reduce 生成最终答案；`only_need_context=True` 时直接返回 points context。详见 `learn/topics/global-query-flow.md`。
- Q: map 阶段的 prompt（`global_map_rag_points`）在说什么？
  A: 它要求模型基于社区表格上下文提炼 `points`（description+score），输出严格 JSON；这些 points 不是最终回答，而是给 reduce 阶段做综合输入。详见 `learn/topics/global-map-rag-points-prompt.md`。
- Q: reduce 阶段的 prompt（`global_reduce_rag_response`）在说什么？
  A: 它要求模型综合多位“分析师”高分要点，按目标长度与格式产出最终答案，并移除无关信息、保持证据约束。详见 `learn/topics/global-reduce-rag-response-prompt.md`。
- Q: `local_query` 的完整流程是怎样的？
  A: 它是实体中心检索：先用实体向量召回 top-k 实体，再扩展相关社区/关系/文本，拼成四段 CSV 上下文（Reports/Entities/Relationships/Sources），最后用 `local_rag_response` 生成答案。详见 `learn/topics/local-query-flow.md`。
